name: UpdateDashboard

on:
  push:
  schedule:
    - cron: '0 2 * * *'  # Runs every day at 2am


jobs:
  update-dashboard:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      actions: read
      checks: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install PyGithub

      - name: Update dashboard
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          python - <<EOF
          import os
          import json
          from github import Github, UnknownObjectException
          from datetime import datetime

          # Initialize GitHub client
          g = Github(os.environ['GITHUB_TOKEN'])

          # Prepare file to create
          new_run_file = "log_" + datetime.now().strftime('%Y_%m_%d') + ".md"
          new_run_file_text = f"| Owner | Repository | Workflow | Status | Last Run | URL |\n"
          new_run_file_text += f"| ----- | ---------- | -------- | ------ | -------- | --- |\n"

          # Update the previous.md file
          repo = g.get_repo("jburel/ome-resources-monitor")
          contents = repo.get_contents("./logs/previous.md")
          previous_runs = contents.decoded_content.decode()
          
          # Check the list of entries. Add new one at the top and remove the last one
          lines = previous_runs.splitlines()
          logs = []
          file_exist = False
          for line in lines:
              if line.startswith("[log"):
                  logs.append(line)
                  # check the name and see if it exists
                  name = line.split("[")[1].split("]")[0]
                  if name == new_run_file:
                      file_exist = True
          new_lines = [x for x in lines if (x not in logs)]

          name = None
          # remove the last entry and delete the log file
          if len(logs) >= 30:  # max 30 days
              last = logs.pop()
              name = last.split("[")[1].split("]")[0]
              # delete the log file
              contents = repo.get_contents("./logs/" + name)
              repo.delete_file(contents.path, "Remove file", contents.sha)

          if not file_exist: 
              logs[0:0] = [f"[{new_run_file}]({new_run_file})  "]
          result = new_lines + logs
          previous_runs = "\n".join(result)
          contents = repo.get_contents("./logs/previous.md")
          repo.update_file(contents.path, "Add new entries", previous_runs, contents.sha)
 

          # Prepare the dashboard content
          with open("base_text.txt", "r") as file:
              dashboard = file.read()

          # Read the repositories
          with open("repositories.json", 'r') as file:
            data = json.load(file)
          entries = data["@graph"]
          run_text = ""
          for entry in entries:
              repo = g.get_repo(entry["repository"])
              workflows = repo.get_workflows()
              values = []
              # Check if the "workflows" entry is set
              value = entry.get("workflows")
              if value is not None:
                  dirty_values = value.split(",")
                  values = [item.lstrip() for item in dirty_values]

              set_branch = repo.default_branch
              for workflow in workflows:

                  # restrict to the specified workflows if set
                  if len(values) != 0 and workflow.name not in values:
                      continue
                  runs = workflow.get_runs(status='completed', branch=set_branch)
                  if runs.totalCount > 0:
                      latest_run = runs[0]
                      status = latest_run.conclusion.lower()
                      
                      # Create status badge
                      if status == 'success':
                          badge = f"![Success](https://img.shields.io/badge/Success-brightgreen)"
                      elif status == 'failure':
                          badge = f"![Failure](https://img.shields.io/badge/Failure-red)"
                      else:
                          badge = f"![{status.capitalize()}](https://img.shields.io/badge/{status.capitalize()}-yellow)"
                      
                      # Format last run date
                      last_run = latest_run.created_at.strftime("%Y-%m-%d %H:%M:%S")
                      run_text += f"| {repo.owner.login} | [{repo.name}]({repo.html_url}) | {workflow.name} | {badge} | {last_run} | [{latest_run.id}]({latest_run.html_url}) |\n"
          
          dashboard += run_text
          # Add update timestamp
          timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
          dashboard += f"\n\n*Last updated: {timestamp}*"

          # Update the README.md file
          repo = g.get_repo("jburel/ome-resources-monitor")
          contents = repo.get_contents("README.md")
          repo.update_file(contents.path, "Update dashboard", dashboard, contents.sha)

          # Create log file
          new_run_file_text += run_text
          new_run_file_text += f"\n\n*Last updated: {timestamp}*"
          # Check if the file exists
          value = './logs/' + new_run_file
          try:
              contents = repo.get_contents(value)
              # File exits so we update
              repo.update_file(contents.path, "Update log", new_run_file_text, contents.sha)
          except UnknownObjectException:
              # File does not exist so we create it
              repo.create_file(value, 'Create new log', new_run_file_text)

          print("Dashboard updated successfully!")
          EOF

